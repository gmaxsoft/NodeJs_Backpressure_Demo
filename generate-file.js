const fs = require('fs');
const path = require('path');

/**
 * Skrypt do generowania du≈ºego pliku testowego (100MB)
 * 
 * U≈ºywa: fs.writeFileSync('large.txt', 'a'.repeat(100 * 1024 * 1024))
 * 
 * To tworzy plik sk≈ÇadajƒÖcy siƒô z 100MB znaku 'a'.
 */
function generateLargeFile() {
  const filePath = path.join(__dirname, 'large.txt');
  const fileSize = 100 * 1024 * 1024; // 100MB
  const chunkSize = 1024 * 1024; // 1MB na raz (aby uniknƒÖƒá problem√≥w z pamiƒôciƒÖ)
  
  console.log('üìù Generowanie pliku testowego...');
  console.log(`   Rozmiar: ${(fileSize / 1024 / 1024).toFixed(2)} MB`);
  console.log(`   ≈öcie≈ºka: ${filePath}`);
  
  const startTime = Date.now();
  
  // Tworzymy write stream dla lepszej wydajno≈õci
  const writeStream = fs.createWriteStream(filePath);
  const chunk = 'a'.repeat(chunkSize);
  const chunksCount = Math.ceil(fileSize / chunkSize);
  
  let written = 0;
  
  return new Promise((resolve, reject) => {
    writeStream.on('error', reject);
    
    writeStream.on('finish', () => {
      const duration = ((Date.now() - startTime) / 1000).toFixed(2);
      console.log(`\n‚úÖ Plik wygenerowany pomy≈õlnie!`);
      console.log(`‚è±Ô∏è  Czas: ${duration}s`);
      
      // Sprawdzamy rzeczywisty rozmiar
      const stats = fs.statSync(filePath);
      console.log(`üìä Rzeczywisty rozmiar: ${(stats.size / 1024 / 1024).toFixed(2)} MB`);
      resolve();
    });
    
    function writeChunk() {
      if (written < chunksCount) {
        const remaining = fileSize - (written * chunkSize);
        const currentChunkSize = Math.min(chunkSize, remaining);
        
        if (currentChunkSize < chunkSize) {
          // Ostatni chunk mo≈ºe byƒá mniejszy
          const lastChunk = 'a'.repeat(currentChunkSize);
          if (writeStream.write(lastChunk)) {
            written++;
            writeStream.end();
          } else {
            writeStream.once('drain', () => {
              writeStream.end();
            });
          }
        } else {
          const canContinue = writeStream.write(chunk);
          written++;
          
          if (written % 10 === 0) {
            console.log(`   Zapisano: ${(written * chunkSize / 1024 / 1024).toFixed(2)} MB`);
          }
          
          if (!canContinue) {
            // Backpressure - czekamy na drain
            writeStream.once('drain', writeChunk);
          } else {
            // Kontynuujemy asynchronicznie
            setImmediate(writeChunk);
          }
        }
      } else {
        // Wszystkie chunki zapisane, zamykamy strumie≈Ñ
        writeStream.end();
      }
    }
    
    writeChunk();
  });
}

// Uruchomienie
if (require.main === module) {
  generateLargeFile().catch((error) => {
    console.error('‚ùå B≈ÇƒÖd podczas generowania pliku:', error.message);
    process.exit(1);
  });
}

module.exports = { generateLargeFile };
